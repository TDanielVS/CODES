import csv  # files csv: tables
import numpy as np
import matplotlib.image as mpimg
from keras.models import Sequential, Model
from keras.layers import Flatten, Dense, Lambda, Cropping2D, AveragePooling2D, Dropout, MaxPooling2D
from keras.layers.convolutional import Convolution2D
from sklearn.model_selection import train_test_split
import sklearn
import time
import matplotlib.pyplot as plt
import random

#path = '/home/dv_user/Documents/extend/' #38187
path = '/home/dv_user/Documents/Cextrema/' #42006

name = "train_2nd"
Angulo = 3
plotear = True
BINS = 200

path_image = path + 'IMG/'

print("path: ", path_image)

###############
samples = []
angulos = []

with open(path + 'driving_log.csv') as csvfile:  # reading of file csv
    reader = csv.reader(csvfile)

    for line in reader:
        angle = float(line[3])  # Steering angle
        samples.append(line)
        angulos.append(angle)

img_name = samples[0][0].split('\\')[-1]
print(img_name)
if plotear:
    plt.hist(angulos, normed=False, bins=BINS)
    plt.show()

image_test = mpimg.imread(path_image + img_name)
print("image shape: ", image_test.shape)


## Balance data #####
val_max = max(set(angulos), key=angulos.count)
print(val_max)
times = angulos.count(val_max)
print(times)
seconds = angulos.copy()

for i in range(times):  # remove most repeated value
    seconds.remove(val_max)

val = max(set(seconds), key=seconds.count)  # Get most repeated
print(val)
times = seconds.count(val)  # Get concurrences
print(times)
if plotear:
    plt.hist(seconds, normed=False, bins=BINS)
    plt.show()
seconds.clear()

cleared_samples = []
angulos2 = []
angulosFlip = []
count = 0

samples2 = samples.copy()
random.shuffle(samples2)
limite = int(times * 0.5)
print("limit:", limite)
angulos.clear()
for i, data in enumerate(samples2):
    angulos2.append(data[Angulo])
    val_max = angulos2.count(data[Angulo])
    if val_max <= limite:
        cleared_samples.append(data)
        angulos.append(float(data[Angulo]))
        angulosFlip.append(float(data[Angulo]))
        angulosFlip.append(-float(data[Angulo]))

print("samples: ", len(samples))
random.shuffle(cleared_samples)
samples = cleared_samples
num = len(samples)
print("Taken: ", num)
print("Taken + Flip:", num*2)

if plotear:
    plt.hist(angulos, normed=False, bins=BINS)
    plt.show()

    plt.hist(angulosFlip, normed=False, bins=BINS)
    plt.show()



def generator(samples, batch_size=32):
    num_samples = len(samples)
    while 1:  # Loop forever so the generator never terminates
        samples = sklearn.utils.shuffle(samples)
        for offset in range(0, num_samples, batch_size):
            batch_samples = samples[offset:offset + batch_size]
            images, steering = [], []
            for batch_sample in batch_samples:
                angle = float(batch_sample[3])  # Steering angle
                image_name = batch_sample[0].split('\\')[-1]  # name of center
                image = mpimg.imread(path_image + image_name)
                image_flipped = np.fliplr(image)
                images.append(image)  # append image to array
                steering.append(angle)  # append steering angle to array
                images.append(image_flipped)  # flipped
                steering.append(-angle)  # flipped
            x_train = np.array(images)
            y_train = np.array(steering)
            yield sklearn.utils.shuffle(x_train, y_train)


train_samples, validation_samples = train_test_split(samples, test_size=0.2) # 0.25
# compile and train the model using the generator function
train_generator = generator(train_samples, batch_size=16)
validation_generator = generator(validation_samples, batch_size=16)

# Nvidia2
#"""
model = Sequential()
model.add(Cropping2D(cropping=((80, 20), (0, 0)), input_shape=(160, 320, 3)))
model.add(AveragePooling2D(pool_size=(1,4), name="Resize", trainable=False))
model.add(Lambda(lambda x: x/127.5 - 1., name="Normalize")) # lambda x: x/127.5 - 1.
model.add(Convolution2D(3, 5, 5, subsample=(2,2), activation="relu"))
model.add(Convolution2D(24, 3, 3, subsample=(2,2), activation="relu"))
model.add(Convolution2D(36, 3, 3, subsample=(1,1), activation="relu"))
model.add(Convolution2D(48, 3, 3, subsample=(1,1), activation="relu"))
model.add(Convolution2D(64, 3, 3, activation="relu"))
model.add(Convolution2D(64, 3, 3, activation="relu"))
model.add(Dropout(0.1))
model.add(Flatten())
model.add(Dense(100, activation="relu"))
model.add(Dense(50, activation="relu"))
model.add(Dense(10, activation="relu"))
model.add(Dense(1, trainable=False))
#"""

for numb in range(10):
    start_time = time.time()
    #numb = 10
    model.compile(loss='mse', optimizer='adam')
    model.summary()
    history_object = model.fit_generator(train_generator, samples_per_epoch=len(train_samples)*2,
                        validation_data=validation_generator, nb_val_samples=len(validation_samples), nb_epoch=2)

    model.save(name+str(numb)+'.h5')

    elapsed_time = time.time() - start_time
    print('Tiempo: %.3f[s]' % (elapsed_time))

    plt.plot(history_object.history['loss'], label='train')
    plt.plot(history_object.history['val_loss'], label='val')
    plt.title('model loss')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper right')
    plt.savefig(name+str(numb)+".jpg")
    plt.clf()
    #plt.show()

exit()